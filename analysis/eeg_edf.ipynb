{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy pandas scipy plotly scikit-learn lempel_ziv_complexity ordpy antropy jupytext mne PyQt6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import mne\n",
    "\n",
    "from utils import json_to_edf, inspect_resting_eeg\n",
    "\n",
    "pd.set_option('display.max_rows', 300)\n",
    "pd.set_option('display.max_columns', 300)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "DATADIR = Path(\"./data\")\n",
    "for fn in sorted(list(DATADIR.glob(\"*.edf\"))): \n",
    "    print(fn.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = json_to_edf(\n",
    "    'sensor_data.jsonl',\n",
    "    'data/boundless_bob_20260225.edf',\n",
    "    subject_name='bob',\n",
    "    include_motion=True,\n",
    "    include_ppg=True,\n",
    "    line_freq=60  # Use 50 for Europe\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = DATADIR / \"participant_419_eeg_raw.edf\"\n",
    "#file_path = DATADIR / \"S01-1_annotated.edf\"\n",
    "file_path = DATADIR / \"boundless_bob_20260225.edf\"\n",
    "\n",
    "raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "print(raw.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_resting_eeg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sec = 7*60\n",
    "fig, raw = inspect_resting_eeg(\n",
    "    'data/boundless_bob_20260225.edf', \n",
    "    eeg_channels=['AF8', 'AF7', 'TP9', 'TP10'],\n",
    "    time_window=(start_sec, start_sec+30)\n",
    ")\n",
    "fig.savefig(\"bob.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyes open/closed analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = mne.io.read_raw_edf(file_path, preload=True)\n",
    "print(raw.info)\n",
    "\n",
    "print(\"Unique annotations:\")\n",
    "print(np.unique(raw.annotations.description))\n",
    "print(\"\\nAnnotation details:\")\n",
    "for i, (onset, duration, description) in enumerate(zip(raw.annotations.onset, raw.annotations.duration, raw.annotations.description)):\n",
    "    print(f\"{i}: {onset:.2f}s - {duration:.2f}s: {description}\")\n",
    "    if i > 20:  # Limit output\n",
    "        print(\"... (truncated)\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsplt = raw.plot(start=3, duration=120, n_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.plot_psd(fmax=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power Spectral Analysis: Eyes Open vs Eyes Closed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract epochs for each condition\n",
    "# Based on annotations, create epochs for Eyes Open and Eyes Closed conditions\n",
    "\n",
    "# Find events based on annotations\n",
    "events = mne.events_from_annotations(raw)\n",
    "event_dict = events[1]  # Dictionary mapping event names to codes\n",
    "print(\"Available events:\", event_dict)\n",
    "\n",
    "# Create epochs dictionary to store different conditions\n",
    "epochs_dict = {}\n",
    "\n",
    "# Extract epochs for each condition\n",
    "for condition_name, event_code in event_dict.items():\n",
    "    if 'open' in condition_name.lower() or 'close' in condition_name.lower():\n",
    "        # Create events array for this condition\n",
    "        condition_events = events[0][events[0][:, 2] == event_code]\n",
    "        \n",
    "        if len(condition_events) > 0:\n",
    "            # Create epochs for this condition (2 second epochs with 0.5s overlap)\n",
    "            epochs = mne.Epochs(raw, condition_events, \n",
    "                              event_id={condition_name: event_code},\n",
    "                              tmin=0, tmax=2.0,  # 2 second epochs\n",
    "                              baseline=None,\n",
    "                              preload=True,\n",
    "                              verbose=False)\n",
    "            epochs_dict[condition_name] = epochs\n",
    "            print(f\"Created {len(epochs)} epochs for condition: {condition_name}\")\n",
    "\n",
    "print(f\"\\nTotal conditions found: {len(epochs_dict)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Power Spectral Density for each condition\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Parameters for PSD analysis\n",
    "fmin, fmax = 0.5, 50  # Frequency range\n",
    "alpha_band = (8, 12)  # Alpha band definition\n",
    "\n",
    "psd_dict = {}\n",
    "freqs = None\n",
    "\n",
    "for condition_name, epochs in epochs_dict.items():\n",
    "    # Compute PSD using Welch's method (updated MNE API)\n",
    "    spectrum = epochs.compute_psd(method='welch', \n",
    "                                 fmin=fmin, fmax=fmax,\n",
    "                                 n_fft=512,\n",
    "                                 n_overlap=256,\n",
    "                                 verbose=False)\n",
    "    psd = spectrum.get_data()  # Get the actual PSD data\n",
    "    freqs = spectrum.freqs     # Get the frequency array\n",
    "    psd_dict[condition_name] = psd\n",
    "    print(f\"PSD computed for {condition_name}: {psd.shape}\")\n",
    "\n",
    "print(f\"Frequency range: {freqs[0]:.2f} - {freqs[-1]:.2f} Hz\")\n",
    "print(f\"Number of frequency bins: {len(freqs)}\")\n",
    "print(f\"Number of channels: {psd.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alpha band analysis\n",
    "# Extract alpha band power for each condition and channel\n",
    "\n",
    "alpha_freq_mask = (freqs >= alpha_band[0]) & (freqs <= alpha_band[1])\n",
    "alpha_power_dict = {}\n",
    "\n",
    "for condition_name, psd in psd_dict.items():\n",
    "    # Average power in alpha band (8-12 Hz) for each epoch and channel\n",
    "    alpha_power = np.mean(psd[:, :, alpha_freq_mask], axis=2)  # Average over frequency\n",
    "    alpha_power_dict[condition_name] = alpha_power\n",
    "    print(f\"Alpha power shape for {condition_name}: {alpha_power.shape}\")\n",
    "    print(f\"Alpha power range for {condition_name}: {alpha_power.min():.2e} - {alpha_power.max():.2e}\")\n",
    "\n",
    "# Get channel names\n",
    "ch_names = epochs_dict[list(epochs_dict.keys())[0]].ch_names\n",
    "print(f\"\\nChannels: {ch_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison between conditions\n",
    "# Perform paired t-tests for alpha power between conditions\n",
    "\n",
    "condition_names = list(alpha_power_dict.keys())\n",
    "print(\"Statistical comparison of alpha power between conditions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(condition_names) >= 2:\n",
    "    # Compare first two conditions (should be Eyes Open vs Eyes Closed)\n",
    "    cond1_name, cond2_name = condition_names[0], condition_names[1]\n",
    "    cond1_alpha = alpha_power_dict[cond1_name]\n",
    "    cond2_alpha = alpha_power_dict[cond2_name]\n",
    "    \n",
    "    # For each channel, compare alpha power between conditions\n",
    "    results = []\n",
    "    for ch_idx, ch_name in enumerate(ch_names):\n",
    "        # Get alpha power for this channel across all epochs\n",
    "        cond1_ch_alpha = cond1_alpha[:, ch_idx]\n",
    "        cond2_ch_alpha = cond2_alpha[:, ch_idx]\n",
    "        \n",
    "        # Paired t-test (if we have paired data) or independent t-test\n",
    "        from scipy.stats import ttest_ind\n",
    "        t_stat, p_value = ttest_ind(cond1_ch_alpha, cond2_ch_alpha)\n",
    "        \n",
    "        # Calculate effect size (Cohen's d)\n",
    "        pooled_std = np.sqrt(((len(cond1_ch_alpha) - 1) * np.var(cond1_ch_alpha, ddof=1) + \n",
    "                             (len(cond2_ch_alpha) - 1) * np.var(cond2_ch_alpha, ddof=1)) / \n",
    "                            (len(cond1_ch_alpha) + len(cond2_ch_alpha) - 2))\n",
    "        cohens_d = (np.mean(cond1_ch_alpha) - np.mean(cond2_ch_alpha)) / pooled_std\n",
    "        \n",
    "        results.append({\n",
    "            'channel': ch_name,\n",
    "            'cond1_mean': np.mean(cond1_ch_alpha),\n",
    "            'cond2_mean': np.mean(cond2_ch_alpha),\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'significant': p_value < 0.05\n",
    "        })\n",
    "        \n",
    "        print(f\"{ch_name:12} | {cond1_name}: {np.mean(cond1_ch_alpha):.2e} | \"\n",
    "              f\"{cond2_name}: {np.mean(cond2_ch_alpha):.2e} | \"\n",
    "              f\"t={t_stat:.3f}, p={p_value:.4f}, d={cohens_d:.3f} {'*' if p_value < 0.05 else ''}\")\n",
    "    \n",
    "    # Summary\n",
    "    significant_channels = [r for r in results if r['significant']]\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Channels with significant differences: {len(significant_channels)}/{len(results)}\")\n",
    "    if significant_channels:\n",
    "        print(\"Significant channels:\", [r['channel'] for r in significant_channels])\n",
    "        \n",
    "else:\n",
    "    print(\"Need at least 2 conditions for comparison\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Power Spectra Comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Power Spectral Analysis: Eyes Open vs Eyes Closed', fontsize=16)\n",
    "\n",
    "# Plot 1: Average power spectra across all channels\n",
    "ax1 = axes[0, 0]\n",
    "for condition_name, psd in psd_dict.items():\n",
    "    # Average across epochs and channels\n",
    "    mean_psd = np.mean(np.mean(psd, axis=0), axis=0)\n",
    "    ax1.semilogy(freqs, mean_psd, label=condition_name, linewidth=2)\n",
    "\n",
    "ax1.axvspan(alpha_band[0], alpha_band[1], alpha=0.3, color='gray', label='Alpha band')\n",
    "ax1.set_xlabel('Frequency (Hz)')\n",
    "ax1.set_ylabel('Power (μV²/Hz)')\n",
    "ax1.set_title('Average Power Spectrum (All Channels)')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Alpha power comparison by channel\n",
    "if len(condition_names) >= 2:\n",
    "    ax2 = axes[0, 1]\n",
    "    cond1_alpha_mean = np.mean(alpha_power_dict[condition_names[0]], axis=0)\n",
    "    cond2_alpha_mean = np.mean(alpha_power_dict[condition_names[1]], axis=0)\n",
    "    \n",
    "    x_pos = np.arange(len(ch_names))\n",
    "    width = 0.35\n",
    "    \n",
    "    ax2.bar(x_pos - width/2, cond1_alpha_mean, width, label=condition_names[0], alpha=0.8)\n",
    "    ax2.bar(x_pos + width/2, cond2_alpha_mean, width, label=condition_names[1], alpha=0.8)\n",
    "    \n",
    "    ax2.set_xlabel('Channel')\n",
    "    ax2.set_ylabel('Alpha Power (μV²/Hz)')\n",
    "    ax2.set_title('Alpha Power by Channel')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(ch_names, rotation=45)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Alpha power ratio (Closed/Open)\n",
    "if len(condition_names) >= 2:\n",
    "    ax3 = axes[1, 0]\n",
    "    ratio = cond2_alpha_mean / cond1_alpha_mean\n",
    "    colors = ['red' if r > 1 else 'blue' for r in ratio]\n",
    "    \n",
    "    bars = ax3.bar(ch_names, ratio, color=colors, alpha=0.7)\n",
    "    ax3.axhline(y=1, color='black', linestyle='--', alpha=0.5)\n",
    "    ax3.set_xlabel('Channel')\n",
    "    ax3.set_ylabel(f'Alpha Power Ratio ({condition_names[1]}/{condition_names[0]})')\n",
    "    ax3.set_title('Alpha Power Ratio by Channel')\n",
    "    ax3.set_xticklabels(ch_names, rotation=45)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add text annotations for significant differences\n",
    "    for i, (bar, result) in enumerate(zip(bars, results)):\n",
    "        if result['significant']:\n",
    "            height = bar.get_height()\n",
    "            ax3.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                    '*', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
    "\n",
    "# Plot 4: Topographic representation (if channels are available)\n",
    "ax4 = axes[1, 1]\n",
    "if len(condition_names) >= 2:\n",
    "    # Simple bar plot showing effect sizes\n",
    "    effect_sizes = [r['cohens_d'] for r in results]\n",
    "    p_values = [r['p_value'] for r in results]\n",
    "    colors = ['red' if p < 0.05 else 'gray' for p in p_values]\n",
    "    \n",
    "    bars = ax4.bar(ch_names, effect_sizes, color=colors, alpha=0.7)\n",
    "    ax4.axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "    ax4.set_xlabel('Channel')\n",
    "    ax4.set_ylabel(\"Cohen's d (Effect Size)\")\n",
    "    ax4.set_title('Effect Size by Channel (Red = Significant)')\n",
    "    ax4.set_xticklabels(ch_names, rotation=45)\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional Analysis: Frequency Band Comparison\n",
    "# Compare multiple frequency bands between conditions\n",
    "\n",
    "frequency_bands = {\n",
    "    'Delta': (0.5, 4),\n",
    "    'Theta': (4, 8),\n",
    "    'Alpha': (8, 12),\n",
    "    'Beta': (12, 30),\n",
    "    'Gamma': (30, 50)\n",
    "}\n",
    "\n",
    "print(\"Frequency Band Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(condition_names) >= 2:\n",
    "    band_results = {}\n",
    "    \n",
    "    for band_name, (f_low, f_high) in frequency_bands.items():\n",
    "        band_mask = (freqs >= f_low) & (freqs <= f_high)\n",
    "        band_power_dict = {}\n",
    "        \n",
    "        for condition_name, psd in psd_dict.items():\n",
    "            # Average power in this frequency band\n",
    "            band_power = np.mean(psd[:, :, band_mask], axis=2)  # Average over frequency\n",
    "            band_power_dict[condition_name] = band_power\n",
    "        \n",
    "        # Statistical comparison for this band\n",
    "        cond1_band = band_power_dict[condition_names[0]]\n",
    "        cond2_band = band_power_dict[condition_names[1]]\n",
    "        \n",
    "        # Average across all channels and epochs\n",
    "        cond1_mean = np.mean(cond1_band)\n",
    "        cond2_mean = np.mean(cond2_band)\n",
    "        \n",
    "        # T-test across all data points\n",
    "        cond1_flat = cond1_band.flatten()\n",
    "        cond2_flat = cond2_band.flatten()\n",
    "        t_stat, p_value = ttest_ind(cond1_flat, cond2_flat)\n",
    "        \n",
    "        # Effect size\n",
    "        pooled_std = np.sqrt(((len(cond1_flat) - 1) * np.var(cond1_flat, ddof=1) + \n",
    "                             (len(cond2_flat) - 1) * np.var(cond2_flat, ddof=1)) / \n",
    "                            (len(cond1_flat) + len(cond2_flat) - 2))\n",
    "        cohens_d = (cond1_mean - cond2_mean) / pooled_std\n",
    "        \n",
    "        band_results[band_name] = {\n",
    "            'cond1_mean': cond1_mean,\n",
    "            'cond2_mean': cond2_mean,\n",
    "            'ratio': cond1_mean / cond2_mean,\n",
    "            't_stat': t_stat,\n",
    "            'p_value': p_value,\n",
    "            'cohens_d': cohens_d,\n",
    "            'significant': p_value < 0.05\n",
    "        }\n",
    "        \n",
    "        print(f\"{band_name:8} ({f_low:2.0f}-{f_high:2.0f} Hz) | \"\n",
    "              f\"{condition_names[0]}: {cond1_mean:.2e} | \"\n",
    "              f\"{condition_names[1]}: {cond2_mean:.2e} | \"\n",
    "              f\"Ratio: {cond1_mean/cond2_mean:.3f} | \"\n",
    "              f\"t={t_stat:.3f}, p={p_value:.4f}, d={cohens_d:.3f} \"\n",
    "              f\"{'***' if p_value < 0.001 else '**' if p_value < 0.01 else '*' if p_value < 0.05 else ''}\")\n",
    "    \n",
    "    print(f\"\\n*** p < 0.001, ** p < 0.01, * p < 0.05\")\n",
    "    \n",
    "    # Summary of significant bands\n",
    "    significant_bands = [band for band, result in band_results.items() if result['significant']]\n",
    "    if significant_bands:\n",
    "        print(f\"\\nSignificant frequency bands: {', '.join(significant_bands)}\")\n",
    "        \n",
    "        # Alpha band specific findings\n",
    "        if 'Alpha' in significant_bands:\n",
    "            alpha_result = band_results['Alpha']\n",
    "            print(f\"\\nAlpha Band Findings:\")\n",
    "            print(f\"- Alpha power is {alpha_result['ratio']:.2f}x higher in {condition_names[0]} vs {condition_names[1]}\")\n",
    "            print(f\"- Effect size (Cohen's d): {alpha_result['cohens_d']:.3f}\")\n",
    "            print(f\"- Statistical significance: p = {alpha_result['p_value']:.4f}\")\n",
    "            \n",
    "            if alpha_result['ratio'] > 1:\n",
    "                print(f\"- This suggests increased alpha activity during {condition_names[0]}\")\n",
    "            else:\n",
    "                print(f\"- This suggests decreased alpha activity during {condition_names[0]}\")\n",
    "    else:\n",
    "        print(\"\\nNo significant differences found in any frequency band.\")\n",
    "        \n",
    "else:\n",
    "    print(\"Need at least 2 conditions for comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive EEG Plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure interactive plotting for MNE\n",
    "# Option 1: Use Qt backend for native MNE interactive plots\n",
    "%matplotlib qt\n",
    "\n",
    "# Alternative: If you prefer plots within the notebook, use:\n",
    "# %matplotlib widget  \n",
    "\n",
    "# Set MNE to use the interactive browser backend\n",
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')  # or 'TkAgg' if Qt is not available\n",
    "\n",
    "print(\"Interactive plotting configured!\")\n",
    "print(\"Backend:\", matplotlib.get_backend())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create an interactive plot of the raw EEG data\n",
    "# This will open in a separate window with full MNE interactive capabilities\n",
    "\n",
    "# Interactive raw data browser\n",
    "fig = raw.plot(\n",
    "    start=0,           # Start time in seconds\n",
    "    duration=30,       # Duration to show in seconds  \n",
    "    n_channels=20,     # Number of channels to show at once\n",
    "    scalings='auto',   # Auto-scale channels\n",
    "    title='Interactive EEG Browser - Eyes Open vs Eyes Closed',\n",
    "    show=True,         # Show the plot\n",
    "    block=False        # Don't block execution\n",
    ")\n",
    "\n",
    "print(\"Interactive plot opened in separate window!\")\n",
    "print(\"Use the following controls:\")\n",
    "print(\"- Left/Right arrows: Navigate time\")\n",
    "print(\"- Up/Down arrows: Change amplitude scaling\") \n",
    "print(\"- Page Up/Down: Navigate channels\")\n",
    "print(\"- 'a': Toggle annotation mode\")\n",
    "print(\"- Space: Start/stop scrolling\")\n",
    "print(\"- 'h': Help menu\")\n",
    "print(\"\\nYou can see the Eyes Open/Closed annotations marked on the timeline!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative: Plotly-based interactive plot (stays in notebook)\n",
    "# If the Qt backend doesn't work, here's a Plotly alternative\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "def create_interactive_eeg_plot(raw, start_time=0, duration=30, channels_to_show=None):\n",
    "    \"\"\"Create an interactive EEG plot using Plotly\"\"\"\n",
    "    \n",
    "    if channels_to_show is None:\n",
    "        # Show all channels except ref and drl\n",
    "        eeg_channels = [ch for ch in raw.ch_names if ch.startswith('eeg')]\n",
    "        channels_to_show = eeg_channels\n",
    "    \n",
    "    # Get data for the specified time window\n",
    "    start_sample = int(start_time * raw.info['sfreq'])\n",
    "    end_sample = int((start_time + duration) * raw.info['sfreq'])\n",
    "\n",
    "    data, times = raw[:, start_sample:end_sample]\n",
    "    #times = times + start_time  # Adjust time offset\n",
    "    #print(f\"{start_sample=}, {end_sample=}, {duration=}, start_time={times[0]}, end_time={times[-1]}\")\n",
    "    \n",
    "    # Create subplot for each channel\n",
    "    fig = make_subplots(\n",
    "        rows=len(channels_to_show), \n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        subplot_titles=[f\"Channel {ch}\" for ch in channels_to_show],\n",
    "        vertical_spacing=0.02\n",
    "    )\n",
    "    \n",
    "    # Add traces for each channel\n",
    "    for i, ch_name in enumerate(channels_to_show):\n",
    "        if ch_name in raw.ch_names:\n",
    "            ch_idx = raw.ch_names.index(ch_name)\n",
    "            y_data = data[ch_idx, :] * 1e6  # Convert to microvolts\n",
    "            \n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=times,\n",
    "                    y=y_data,\n",
    "                    mode='lines',\n",
    "                    name=ch_name,\n",
    "                    line=dict(width=1),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=i+1, col=1\n",
    "            )\n",
    "    \n",
    "    # Add annotations for Eyes Open/Closed periods\n",
    "    for onset, duration_ann, description in zip(raw.annotations.onset, \n",
    "                                               raw.annotations.duration, \n",
    "                                               raw.annotations.description):\n",
    "        if onset >= start_time and onset <= start_time + duration:\n",
    "            color = 'lightblue' if 'Open' in description else 'lightcoral'\n",
    "            fig.add_vrect(\n",
    "                x0=onset, x1=onset + duration_ann,\n",
    "                fillcolor=color, opacity=0.3,\n",
    "                annotation_text=description,\n",
    "                annotation_position=\"top left\"\n",
    "            )\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'EEG Timeseries',\n",
    "        height=120 * len(channels_to_show),\n",
    "        xaxis_title='Time (s)',\n",
    "        showlegend=False,\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Update y-axes\n",
    "    for i in range(len(channels_to_show)):\n",
    "        fig.update_yaxes(title_text='μV', row=i+1, col=1)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create the interactive plot\n",
    "interactive_fig = create_interactive_eeg_plot(raw, start_time=10, duration=110)\n",
    "interactive_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive widget for exploring different time windows\n",
    "# Create a simple widget to change time windows easily\n",
    "\n",
    "def plot_time_window(start_time=0, duration=30, n_channels=8):\n",
    "    \"\"\"Function to plot different time windows\"\"\"\n",
    "    fig = create_interactive_eeg_plot(raw, start_time, duration, \n",
    "                                    channels_to_show=raw.ch_names[:n_channels])\n",
    "    fig.show()\n",
    "    \n",
    "# You can call this function to explore different time windows:\n",
    "print(\"Use this function to explore different time windows:\")\n",
    "print(\"plot_time_window(start_time=60, duration=30)  # Show 60-90s\")\n",
    "print(\"plot_time_window(start_time=120, duration=45) # Show 120-165s\")\n",
    "print(\"plot_time_window(start_time=180, duration=60) # Show 180-240s\")\n",
    "print()\n",
    "print(\"Or modify parameters:\")\n",
    "print(\"plot_time_window(start_time=0, duration=120, n_channels=12)  # Longer window, more channels\")\n",
    "\n",
    "# Example: Show the transition between first Eyes Open and Eyes Closed periods\n",
    "print(\"\\nShowing transition from Eyes Open to Eyes Closed (around 60s):\")\n",
    "transition_fig = create_interactive_eeg_plot(raw, start_time=50, duration=30)\n",
    "transition_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.io import loadmat\n",
    "import plotly.express as px\n",
    "\n",
    "d = loadmat(\"/Users/bobd/git/eeg-recorder/analysis/data/ding_2025/data.mat\")\n",
    "evoke = d['evoke']\n",
    "print(f\"{evoke.shape=}\")\n",
    "itpc = d['itpc']\n",
    "print(f\"{itpc.shape=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from scipy import stats\n",
    "\n",
    "# Calculate mean across trials and participants for channel -2\n",
    "evoke_mn = evoke.mean(axis=2).mean(axis=0)\n",
    "freq = np.linspace(1, 30, evoke_mn.shape[1])\n",
    "\n",
    "# Calculate 95% confidence intervals\n",
    "# First get data for channel -2 across all trials and participants\n",
    "channel_data = evoke[:, :, :, -2]  # shape: (participants, channels, trials)\n",
    "# Average across channels (axis=1) to get (participants, trials) \n",
    "channel_data_avg = channel_data.mean(axis=1)  # shape: (participants, trials)\n",
    "# Now we have data points across participants and trials for statistical analysis\n",
    "\n",
    "# Calculate mean and standard error across all data points\n",
    "all_freq_data = []\n",
    "for freq_idx in range(evoke_mn.shape[1]):\n",
    "    # Get all data points for this frequency (across participants and trials)\n",
    "    freq_data = evoke[:, :, :, freq_idx].mean(axis=1)  # Average across channels first\n",
    "    freq_data_flat = freq_data.flatten()  # Flatten to get all data points\n",
    "    all_freq_data.append(freq_data_flat)\n",
    "\n",
    "# Calculate mean, standard error, and 95% CI for each frequency\n",
    "means = []\n",
    "ci_lower = []\n",
    "ci_upper = []\n",
    "\n",
    "for freq_data in all_freq_data:\n",
    "    mean_val = np.mean(freq_data)\n",
    "    sem = stats.sem(freq_data)  # Standard error of the mean\n",
    "    ci = stats.t.interval(0.95, len(freq_data)-1, loc=mean_val, scale=sem)\n",
    "    \n",
    "    means.append(mean_val)\n",
    "    ci_lower.append(ci[0])\n",
    "    ci_upper.append(ci[1])\n",
    "\n",
    "means = np.array(means)\n",
    "ci_lower = np.array(ci_lower)\n",
    "ci_upper = np.array(ci_upper)\n",
    "\n",
    "# Create plot with confidence intervals\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the main line\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=freq,\n",
    "    y=means,\n",
    "    mode='lines',\n",
    "    name='Mean',\n",
    "    line=dict(color='blue', width=2)\n",
    "))\n",
    "\n",
    "# Add confidence interval as filled area\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=np.concatenate([freq, freq[::-1]]),  # x coordinates for filled area\n",
    "    y=np.concatenate([ci_upper, ci_lower[::-1]]),  # y coordinates for filled area\n",
    "    fill='toself',\n",
    "    fillcolor='rgba(0,100,200,0.2)',\n",
    "    line=dict(color='rgba(255,255,255,0)'),\n",
    "    name='95% CI',\n",
    "    showlegend=True\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Evoked Response with 95% Confidence Intervals',\n",
    "    xaxis_title='Frequency (Hz)',\n",
    "    yaxis_title='Amplitude',\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itpc_mn = itpc.mean(axis=2).mean(axis=0)\n",
    "px.line(x=freq, y=itpc_mn[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
